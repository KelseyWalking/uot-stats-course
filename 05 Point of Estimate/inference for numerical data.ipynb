{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2847e758-3583-4082-af48-502699dc1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025045202854784173\n"
     ]
    }
   ],
   "source": [
    "'''What proportion of the t-distribution with 18 degrees of freedom falls below -2.10?'''\n",
    "from scipy.stats import t\n",
    "result = t.cdf(-2.10, df=18)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626005b5-e54f-4f40-b6c8-5fe0645d7d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05728041226893965\n"
     ]
    }
   ],
   "source": [
    "'''A t-distribution with 20 degrees of freedom is shown in the left panel of Figure 7.4. Estimate the\n",
    "proportion of the distribution falling above 1.65.'''\n",
    "from scipy.stats import t\n",
    "result = 1-t.cdf(1.65, df=20)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28b74a4-74bf-4cf4-a5aa-c86b2e470229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.095465966266709\n"
     ]
    }
   ],
   "source": [
    "'''A t-distribution with 2 degrees of freedom is shown in the right panel of Figure 7.4. Estimate the\n",
    "proportion of the distribution falling more than 3 units from the mean (above or below).'''\n",
    "'''\n",
    "With so few degrees of freedom, the t-distribution will give a more notably different value than the\n",
    "normal distribution. Under a normal distribution, the area would be about 0.003 using the 68-95-\n",
    "99.7 rule. For a t-distribution with df = 2, the area in both tails beyond 3 units totals 0.0955. This\n",
    "area is dramatically different than what we obtain from the normal distribution.'''\n",
    "from scipy.stats import t\n",
    "result =(1- t.cdf(3, df=2))*2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2478267a-1504-45d7-93f2-8ef4e2a35c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0026997960632601965\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Mean and standard deviation for standard normal distribution\n",
    "mean = 0\n",
    "std_dev = 1\n",
    "\n",
    "# Calculate cumulative probability for -3 and +3\n",
    "prob_below_negative_3 = norm.cdf(-3, loc=mean, scale=std_dev)\n",
    "prob_above_positive_3 = 1 - norm.cdf(3, loc=mean, scale=std_dev)\n",
    "\n",
    "# Total proportion falling more than 3 units from the mean\n",
    "total_proportion = prob_below_negative_3 + prob_above_positive_3\n",
    "\n",
    "print(total_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ed7289-f94f-46bb-843f-baa1c2968512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9552977656658079\n"
     ]
    }
   ],
   "source": [
    "'''What proportion of the t-distribution with 19 degrees of freedom falls above -1.79 units? Use your\n",
    "preferred method for finding tail areas.'''\n",
    "#approve when n is big, the t-distribution and norm-distribution generate very close results. \n",
    "\n",
    "from scipy.stats import t\n",
    "result = 1-t.cdf(-1.79, df=19)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c108d277-a33e-4c1a-b169-fd826a6d09e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9632730443012737\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Mean and standard deviation for standard normal distribution\n",
    "mean = 0\n",
    "std_dev = 1\n",
    "\n",
    "# Calculate cumulative probability for -3 and +3\n",
    "proportion = 1 - norm.cdf(-1.79, loc=mean, scale=std_dev)\n",
    "\n",
    "\n",
    "print(proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90c8ccb7-8358-45a7-b33c-e8beabd44968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.527656187902292, 2.10092204024096)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "We will identify a confidence interval for the average mercury content in dolphin muscle using a\n",
    "sample of 19 Risso’s dolphins from the Taiji area in Japan. The data are summarized in Figure 7.6.\n",
    "The minimum and maximum observed values can be used to evaluate whether or not there are clear\n",
    "outliers.\n",
    "n x s ¯ minimum maximum\n",
    "19 4.4 2.3 1.7 9.2\n",
    "\n",
    "'''\n",
    "x=4.4\n",
    "s=2.3\n",
    "n=19\n",
    "#Using the summary statistics in Figure 7.6, compute the standard error for the average mercury content in the n = 19 dolphins.\n",
    "se= s/(n**(1/2))\n",
    "\n",
    "#When n = 19, what is the appropriate degrees of freedom? Find t⋆df for this degrees of freedom and the confidence level of 95%\n",
    "#Using statistical software, we find the cutoff where the upper tail is equal to 2.5%: t⋆18 = 2.10. The area below -2.10 will also be equal to 2.5%. That is, 95% of the t-distribution with df = 18 lies within 2.10 units of 0.\n",
    "from scipy.stats import t\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n-1\n",
    "\n",
    "# Confidence level\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Calculate the critical value t, use percent point function*\n",
    "alpha = 1 - confidence_level\n",
    "t_star = t.ppf(1 - alpha/2, df)\n",
    "\n",
    "se, t_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59befba0-f228-41b2-a36f-1060325ec9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.508564514833451, 3.2914354851665495)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Compute and interpret the 95% confidence interval for the average mercury content in Risso’s\n",
    "dolphins.'''\n",
    "# we are 95% confident that the average mercury content in dophine is between 3.3 to 5.5  µg/wet gram.\n",
    "confidence_interval_up=x+t_star*se\n",
    "confidence_interval_low=x-t_star*se\n",
    "confidence_interval_up,confidence_interval_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5450a5d2-6611-4e4e-a845-8c71a24ad63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,\n",
       " 1.7613101357748562,\n",
       " 0.01781572339255412,\n",
       " 0.3183790141874667,\n",
       " 0.25562098581253323)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The FDA’s webpage provides some data on mercury content of fish. Based on a sample of 15 croaker\n",
    "white fish (Pacific), a sample mean and standard deviation were computed as 0.287 and 0.069 ppm\n",
    "(parts per million), respectively. The 15 observations ranged from 0.18 to 0.41 ppm. We will assume\n",
    "these observations are independent.\n",
    "Estimate the standard error of ¯x = 0.287 ppm using the data summaries in Guided Practice 7.10.\n",
    "If we are to use the t-distribution to create a 90% confidence interval for the actual mean of the\n",
    "mercury content, identify the degrees of freedom and t⋆df .\n",
    "'''\n",
    "from scipy.stats import t\n",
    "\n",
    "#alpha, df\n",
    "x_bar=0.287\n",
    "conficence_interval=0.9\n",
    "alpha=1-conficence_interval\n",
    "\n",
    "n=15\n",
    "df=n-1\n",
    "\n",
    "#t_star\n",
    "#Since the goal is a 90% confidence interval, we choose t⋆14 so that the two-tail area is 0.1: t⋆14 = 1.76.\n",
    "t_star = t.ppf(1 - alpha/2, df)\n",
    "\n",
    "#se\n",
    "\n",
    "standard_deviation=0.069\n",
    "se=standard_deviation/(n**(1/2))\n",
    "\n",
    "#interval\n",
    "confidence_interval_up=x_bar+t_star*se\n",
    "confidence_interval_low=x_bar-t_star*se\n",
    "\n",
    "df, t_star,se,confidence_interval_up,confidence_interval_low\n",
    "'''\n",
    "The 90% confidence interval from Guided Practice 7.12 is 0.256 ppm to 0.318 ppm. Can we say that\n",
    "90% of croaker white fish (Pacific) have mercury levels between 0.256 and 0.318 ppm?\n",
    "No, a confidence interval only provides a range of plausible values for a population parameter, \n",
    "in this case the population mean. It does not describe what we might observe for individual observations.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef4ac3b7-b942-479b-aaa5-6d4a6c6e06b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.698, 2.373380447585387, 0.009778331619634373, 0.019556663239268746)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Is the typical US runner getting faster or slower over time? We consider this question in the context\n",
    "of the Cherry Blossom Race, which is a 10-mile race in Washington, DC each spring.\n",
    "The average time for all runners who finished the Cherry Blossom Race in 2006 was 93.29\n",
    "minutes (93 minutes and about 17 seconds). We want to determine using data from 100 participants\n",
    "in the 2017 Cherry Blossom Race whether runners in this race are getting faster or slower, versus\n",
    "the other possibility that there has been no change.\n",
    "\n",
    "What are appropriate hypotheses for this context?\n",
    "'''\n",
    "#H0=no change  H0=93.29\n",
    "#Ha~=93.29\n",
    "'''\n",
    "When completing a hypothesis test for the one-sample mean, the process is nearly identical to\n",
    "completing a hypothesis test for a single proportion. First, we find the Z-score using the observed\n",
    "value, null value, and standard error; however, we call it a T-score since we use a t-distribution for\n",
    "calculating the tail area. Then we find the p-value using the same ideas we used previously: find\n",
    "the one-tail area under the sampling distribution, and double it.\n",
    "\n",
    "'''\n",
    "'''\n",
    "The sample mean and sample standard deviation of the sample of 100\n",
    "runners from the 2017 Cherry Blossom Race are 97.32 and 16.98 minutes, respectively. Recall that\n",
    "the sample size is 100 and the average run time in 2006 was 93.29 minutes. Find the test statistic\n",
    "and p-value. What is your conclusion?\n",
    "\n",
    "'''\n",
    "from scipy.stats import t\n",
    "n=100\n",
    "sample_mean=97.32\n",
    "population_mean=93.29\n",
    "sample_standard_deviation=16.98\n",
    "#To find the test statistic (T-score), we first must determine the standard error:\n",
    "se=sample_standard_deviation/(n**(1/2))\n",
    "#Now we can compute the T-score using the sample mean (97.32), null value (93.29), and SE:\n",
    "t_score=(sample_mean-population_mean)/se\n",
    "\n",
    "# Calculate cumulative probability\n",
    "one_tail_area = 1 - t.cdf(t_score, df=n-1)\n",
    "p_value=one_tail_area*2\n",
    "\n",
    "se,t_score,one_tail_area,p_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
